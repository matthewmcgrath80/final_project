{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9cb5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2476, Accuracy: 49.68%, Recall: 0.20, Precision: 0.17, Specificity: 0.80, F1-Score: 0.15\n",
      "Epoch [2/10], Loss: 1.0753, Accuracy: 55.77%, Recall: 0.24, Precision: 0.29, Specificity: 0.82, F1-Score: 0.20\n",
      "Epoch [3/10], Loss: 1.0063, Accuracy: 58.78%, Recall: 0.28, Precision: 0.51, Specificity: 0.85, F1-Score: 0.25\n",
      "Epoch [4/10], Loss: 0.9574, Accuracy: 61.58%, Recall: 0.31, Precision: 0.45, Specificity: 0.86, F1-Score: 0.29\n",
      "Epoch [5/10], Loss: 0.8974, Accuracy: 63.23%, Recall: 0.37, Precision: 0.48, Specificity: 0.87, F1-Score: 0.37\n",
      "Epoch [6/10], Loss: 0.8395, Accuracy: 66.74%, Recall: 0.41, Precision: 0.51, Specificity: 0.88, F1-Score: 0.42\n",
      "Epoch [7/10], Loss: 0.8066, Accuracy: 66.38%, Recall: 0.43, Precision: 0.70, Specificity: 0.88, F1-Score: 0.45\n",
      "Epoch [8/10], Loss: 0.7848, Accuracy: 68.03%, Recall: 0.47, Precision: 0.71, Specificity: 0.89, F1-Score: 0.49\n",
      "Epoch [9/10], Loss: 0.7502, Accuracy: 68.96%, Recall: 0.49, Precision: 0.68, Specificity: 0.89, F1-Score: 0.53\n",
      "Epoch [10/10], Loss: 0.7265, Accuracy: 70.47%, Recall: 0.51, Precision: 0.69, Specificity: 0.90, F1-Score: 0.53\n",
      "Test Accuracy: 79.94%, Recall: 0.41, Precision: 0.37, Specificity: 0.88, F1-Score: 0.37\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassRecall, MulticlassPrecision, MulticlassSpecificity, MulticlassF1Score\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load MobileNetV2\n",
    "\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.classifier[-1] = torch.nn.Linear(\n",
    "    in_features=model.classifier[-1].in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.features[-3].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.features[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.features[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.features[-3].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.features[-2].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.features[-1].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.classifier[-1].parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "recall_macro = MulticlassRecall(num_classes=5, average=\"macro\").to(device)\n",
    "precision_macro = MulticlassPrecision(num_classes=5, average=\"macro\").to(device)\n",
    "specificity_macro = MulticlassSpecificity(num_classes=5, average=\"macro\").to(device)\n",
    "f1score_macro = MulticlassF1Score(num_classes=5, average=\"macro\").to(device)\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    recall_macro.reset()\n",
    "    precision_macro.reset()\n",
    "    specificity_macro.reset()\n",
    "    f1score_macro.reset()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n",
    "model.eval()\n",
    "recall_macro.reset()\n",
    "precision_macro.reset()\n",
    "specificity_macro.reset()\n",
    "f1score_macro.reset()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d510c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0882, Accuracy: 55.63%, Recall: 0.30, Precision: 0.35, Specificity: 0.85, F1-Score: 0.30\n",
      "Epoch [2/10], Loss: 0.8370, Accuracy: 65.45%, Recall: 0.44, Precision: 0.47, Specificity: 0.88, F1-Score: 0.45\n",
      "Epoch [3/10], Loss: 0.6984, Accuracy: 71.90%, Recall: 0.56, Precision: 0.75, Specificity: 0.91, F1-Score: 0.59\n",
      "Epoch [4/10], Loss: 0.5902, Accuracy: 76.13%, Recall: 0.65, Precision: 0.71, Specificity: 0.92, F1-Score: 0.67\n",
      "Epoch [5/10], Loss: 0.4533, Accuracy: 82.08%, Recall: 0.72, Precision: 0.78, Specificity: 0.94, F1-Score: 0.75\n",
      "Epoch [6/10], Loss: 0.3848, Accuracy: 84.52%, Recall: 0.77, Precision: 0.83, Specificity: 0.95, F1-Score: 0.79\n",
      "Epoch [7/10], Loss: 0.2720, Accuracy: 90.11%, Recall: 0.88, Precision: 0.89, Specificity: 0.97, F1-Score: 0.88\n",
      "Epoch [8/10], Loss: 0.2513, Accuracy: 91.11%, Recall: 0.89, Precision: 0.91, Specificity: 0.97, F1-Score: 0.90\n",
      "Epoch [9/10], Loss: 0.2413, Accuracy: 90.97%, Recall: 0.89, Precision: 0.91, Specificity: 0.97, F1-Score: 0.90\n",
      "Epoch [10/10], Loss: 0.1504, Accuracy: 95.13%, Recall: 0.95, Precision: 0.95, Specificity: 0.98, F1-Score: 0.95\n",
      "Test Accuracy: 63.32%, Recall: 0.32, Precision: 0.34, Specificity: 0.88, F1-Score: 0.30\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassRecall, MulticlassPrecision, MulticlassSpecificity, MulticlassF1Score\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load ResNet18\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.fc = torch.nn.Linear(\n",
    "    in_features=model.fc.in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.layer2.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.layer3.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "recall_macro = MulticlassRecall(num_classes=5, average=\"macro\").to(device)\n",
    "precision_macro = MulticlassPrecision(num_classes=5, average=\"macro\").to(device)\n",
    "specificity_macro = MulticlassSpecificity(num_classes=5, average=\"macro\").to(device)\n",
    "f1score_macro = MulticlassF1Score(num_classes=5, average=\"macro\").to(device)\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    recall_macro.reset()\n",
    "    precision_macro.reset()\n",
    "    specificity_macro.reset()\n",
    "    f1score_macro.reset()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n",
    "model.eval()\n",
    "recall_macro.reset()\n",
    "precision_macro.reset()\n",
    "specificity_macro.reset()\n",
    "f1score_macro.reset()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2a470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1134, Accuracy: 54.84%, Recall: 0.26, Precision: 0.40, Specificity: 0.83, F1-Score: 0.25\n",
      "Epoch [2/10], Loss: 0.8615, Accuracy: 64.16%, Recall: 0.41, Precision: 0.44, Specificity: 0.87, F1-Score: 0.40\n",
      "Epoch [3/10], Loss: 0.7439, Accuracy: 70.68%, Recall: 0.51, Precision: 0.71, Specificity: 0.90, F1-Score: 0.53\n",
      "Epoch [4/10], Loss: 0.7067, Accuracy: 71.54%, Recall: 0.53, Precision: 0.62, Specificity: 0.90, F1-Score: 0.56\n",
      "Epoch [5/10], Loss: 0.5642, Accuracy: 76.77%, Recall: 0.65, Precision: 0.75, Specificity: 0.92, F1-Score: 0.68\n",
      "Epoch [6/10], Loss: 0.5476, Accuracy: 78.85%, Recall: 0.67, Precision: 0.76, Specificity: 0.93, F1-Score: 0.70\n",
      "Epoch [7/10], Loss: 0.4486, Accuracy: 82.37%, Recall: 0.76, Precision: 0.81, Specificity: 0.94, F1-Score: 0.78\n",
      "Epoch [8/10], Loss: 0.3651, Accuracy: 86.67%, Recall: 0.83, Precision: 0.86, Specificity: 0.96, F1-Score: 0.84\n",
      "Epoch [9/10], Loss: 0.3000, Accuracy: 88.10%, Recall: 0.82, Precision: 0.87, Specificity: 0.96, F1-Score: 0.85\n",
      "Epoch [10/10], Loss: 0.2555, Accuracy: 90.68%, Recall: 0.88, Precision: 0.92, Specificity: 0.97, F1-Score: 0.90\n",
      "Test Accuracy: 78.80%, Recall: 0.33, Precision: 0.38, Specificity: 0.88, F1-Score: 0.32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassRecall, MulticlassPrecision, MulticlassSpecificity, MulticlassF1Score\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load ResNet18\n",
    "\n",
    "model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.classifier[-1] = torch.nn.Linear(\n",
    "    in_features=model.classifier[-1].in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.features[-3].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.features[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.features[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.features[-3].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.features[-2].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.features[-1].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.classifier[-1].parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "recall_macro = MulticlassRecall(num_classes=5, average=\"macro\").to(device)\n",
    "precision_macro = MulticlassPrecision(num_classes=5, average=\"macro\").to(device)\n",
    "specificity_macro = MulticlassSpecificity(num_classes=5, average=\"macro\").to(device)\n",
    "f1score_macro = MulticlassF1Score(num_classes=5, average=\"macro\").to(device)\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    recall_macro.reset()\n",
    "    precision_macro.reset()\n",
    "    specificity_macro.reset()\n",
    "    f1score_macro.reset()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n",
    "model.eval()\n",
    "recall_macro.reset()\n",
    "precision_macro.reset()\n",
    "specificity_macro.reset()\n",
    "f1score_macro.reset()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        recall_macro.update(predicted, labels)\n",
    "        precision_macro.update(predicted, labels)\n",
    "        specificity_macro.update(predicted, labels)\n",
    "        f1score_macro.update(predicted, labels)\n",
    "    recall = recall_macro.compute().item()\n",
    "    precision = precision_macro.compute().item()\n",
    "    specificity = specificity_macro.compute().item()\n",
    "    f1score = f1score_macro.compute().item()\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%, Recall: {recall:.2f}, Precision: {precision:.2f}, Specificity: {specificity:.2f}, F1-Score: {f1score:.2f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
