{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9cb5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2941, Accuracy: 50.18%\n",
      "Epoch [2/10], Loss: 1.0384, Accuracy: 58.42%\n",
      "Epoch [3/10], Loss: 0.9774, Accuracy: 61.08%\n",
      "Epoch [4/10], Loss: 0.9070, Accuracy: 63.08%\n",
      "Epoch [5/10], Loss: 0.8774, Accuracy: 66.16%\n",
      "Epoch [6/10], Loss: 0.8476, Accuracy: 65.95%\n",
      "Epoch [7/10], Loss: 0.8266, Accuracy: 66.52%\n",
      "Epoch [8/10], Loss: 0.8017, Accuracy: 68.32%\n",
      "Epoch [9/10], Loss: 0.7810, Accuracy: 68.75%\n",
      "Epoch [10/10], Loss: 0.7662, Accuracy: 69.75%\n",
      "Test Accuracy: 76.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load MobileNetV3\n",
    "\n",
    "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.classifier[3] = torch.nn.Linear(\n",
    "    in_features=model.classifier[3].in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.features[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.features[-1].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.classifier[3].parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #print(total)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(total)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d510c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1323, Accuracy: 53.76%\n",
      "Epoch [2/10], Loss: 0.8823, Accuracy: 63.73%\n",
      "Epoch [3/10], Loss: 0.7436, Accuracy: 70.04%\n",
      "Epoch [4/10], Loss: 0.6313, Accuracy: 75.56%\n",
      "Epoch [5/10], Loss: 0.5279, Accuracy: 78.71%\n",
      "Epoch [6/10], Loss: 0.4193, Accuracy: 85.02%\n",
      "Epoch [7/10], Loss: 0.3421, Accuracy: 86.59%\n",
      "Epoch [8/10], Loss: 0.3124, Accuracy: 88.03%\n",
      "Epoch [9/10], Loss: 0.2429, Accuracy: 91.54%\n",
      "Epoch [10/10], Loss: 0.1789, Accuracy: 93.76%\n",
      "Test Accuracy: 73.35%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load ResNet18\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.fc = torch.nn.Linear(\n",
    "    in_features=model.fc.in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #print(total)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(total)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1976, Accuracy: 52.40%\n",
      "Epoch [2/10], Loss: 1.0282, Accuracy: 57.42%\n",
      "Epoch [3/10], Loss: 0.9015, Accuracy: 62.15%\n",
      "Epoch [4/10], Loss: 0.8704, Accuracy: 64.01%\n",
      "Epoch [5/10], Loss: 0.7544, Accuracy: 67.81%\n",
      "Epoch [6/10], Loss: 0.6666, Accuracy: 72.33%\n",
      "Epoch [7/10], Loss: 0.6015, Accuracy: 76.13%\n",
      "Epoch [8/10], Loss: 0.5567, Accuracy: 79.43%\n",
      "Epoch [9/10], Loss: 0.4797, Accuracy: 82.44%\n",
      "Epoch [10/10], Loss: 0.4379, Accuracy: 83.15%\n",
      "Test Accuracy: 71.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(342),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(342),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load Inception_v3\n",
    "\n",
    "model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.fc = torch.nn.Linear(\n",
    "    in_features=model.fc.in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.Mixed_7c.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #print(total)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, aux_outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(total)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485e47c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3044, Accuracy: 48.67%\n",
      "Epoch [2/10], Loss: 1.1391, Accuracy: 51.54%\n",
      "Epoch [3/10], Loss: 1.1442, Accuracy: 51.97%\n",
      "Epoch [4/10], Loss: 1.1289, Accuracy: 52.54%\n",
      "Epoch [5/10], Loss: 1.1256, Accuracy: 53.98%\n",
      "Epoch [6/10], Loss: 1.1096, Accuracy: 52.40%\n",
      "Epoch [7/10], Loss: 1.0706, Accuracy: 54.34%\n",
      "Epoch [8/10], Loss: 1.1029, Accuracy: 53.91%\n",
      "Epoch [9/10], Loss: 1.0639, Accuracy: 55.34%\n",
      "Epoch [10/10], Loss: 1.0908, Accuracy: 54.48%\n",
      "Test Accuracy: 73.07%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Image transformer\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Creates a custom dataset. Initialised with the csv file, image file and transformeded.\n",
    "\n",
    "class messidorDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Get the images and csv data file\n",
    "\n",
    "annotations_file = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor_data.csv\"\n",
    "img_dir = \"/mnt/c/Users/matth/CS408/MESSIDOR-2_from_kaggle/messidor-2/preprocess\"\n",
    "af = pd.read_csv(annotations_file)\n",
    "num_imgs = len(af)\n",
    "\n",
    "# Splits the dataset into training and testing sets in 80:20 ratio respectively\n",
    "\n",
    "train_ratio = 0.8\n",
    "split_id = int(train_ratio * num_imgs)\n",
    "train_index = (range(0, split_id))\n",
    "test_index = (range(split_id, num_imgs))\n",
    "\n",
    "train_dataset = messidorDataset(annotations_file, img_dir, train_transform)\n",
    "test_dataset = messidorDataset(annotations_file, img_dir, test_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_index)\n",
    "test_dataset = Subset(test_dataset, test_index)\n",
    "\n",
    "# Loads the dataset, batchsize and shuffles the dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load VGG11\n",
    "\n",
    "model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# This replaces the final layer of the model to output 5 classes instead of 1000\n",
    "\n",
    "model.classifier[-1] = torch.nn.Linear(\n",
    "    in_features=model.classifier[-1].in_features,\n",
    "    out_features=5\n",
    ")\n",
    "\n",
    "# Freeze all layers except the last two layers.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.classifier[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Uses cuda if available or it uses cpu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.classifier[-2].parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": model.classifier[-1].parameters(), \"lr\": 1e-3},\n",
    "])\n",
    "\n",
    "# Model training\n",
    "\n",
    "total_epoch = 10\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #print(total)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{total_epoch}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Model testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(total)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
